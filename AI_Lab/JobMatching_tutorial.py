import pandas as pd
import json
import os
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ OpenAI API í‚¤ ë¡œë“œ ë° í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
load_dotenv()
openai_api_key = os.environ.get("OPENAI_API_KEY", None)
if openai_api_key is None:
    raise ValueError(".env íŒŒì¼ì— 'OPENAI_API_KEY'ê°€ ì—†ìŠµë‹ˆë‹¤. ë³€ìˆ˜ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
os.environ["OPENAI_API_KEY"] = openai_api_key

# ì§ë¬´ê¸°ìˆ ì„œ ë°ì´í„° ë¡œë“œ (JSON â†’ DataFrame)
json_path = "C:/workspace/fproject/backend-model/AI_Lab/data/job_description.json"
with open(json_path, encoding="utf-8") as f:
    data = json.load(f)
df = pd.DataFrame(data)
df.head()

# ì±„ìš©ê³µê³  ë°ì´í„° ë¡œë“œ (íšŒì‚¬ë³„ JSON â†’ DataFrame)
company_name = "kakao"
jobs_json_path = f"C:/workspace/fproject/backend-model/AI_Lab/data/{company_name}_jobs.json"
with open(jobs_json_path, encoding="utf-8") as f:
    jobs_data = json.load(f)
jobs_df = pd.DataFrame(jobs_data)
jobs_df.drop('html', axis=1, inplace=True)
jobs_df.head()


# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰(Retriever) ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_community.vectorstores import Chroma
from langchain_community.retrievers import BM25Retriever
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document
from langchain_core.retrievers import BaseRetriever
from langchain_core.callbacks import CallbackManagerForRetrieverRun
from langchain_core.runnables import RunnableParallel, RunnablePassthrough
from typing import List

# ì¹´ì¹´ì˜¤, ìš°ì•„í•œí˜•ì œë“¤ ì±„ìš©ê³µê³  ì „ì²´ ë¡œë“œ (ë°ì´í„° ê²°í•©)
kakao_path = "C:/workspace/fproject/backend-model/AI_Lab/data/kakao_jobs.json"
woowahan_path = "C:/workspace/fproject/backend-model/AI_Lab/data/woowahan_jobs.json"
job_postings = []
with open(kakao_path, 'r', encoding='utf-8') as f:
    kakao_jobs = json.load(f)
    job_postings.extend(kakao_jobs)
with open(woowahan_path, 'r', encoding='utf-8') as f:
    woowahan_jobs = json.load(f)
    job_postings.extend(woowahan_jobs)
print(f"ì´ ì±„ìš©ê³µê³  ìˆ˜: {len(job_postings)}")

# ì±„ìš©ê³µê³  ë¦¬ìŠ¤íŠ¸ â†’ LangChain Documentë¡œ ë³€í™˜
documents = []
for job in job_postings:
    skill_set_text = ", ".join(job['skill_set']) if isinstance(job.get('skill_set'), list) else str(job.get('skill_set', ''))
    required_skills_text = ""
    if 'meta_data' in job and job['meta_data']:
        if 'required_skills' in job['meta_data'] and job['meta_data']['required_skills']:
            required_skills_text = ", ".join(job['meta_data']['required_skills'])
    content = f"""
    ì œëª©: {job.get('title', '')}
    íšŒì‚¬: {job.get('company', '')}
    ì§ë¬´ë‚´ìš©: {job.get('description', '')[:500]}
    ì—…ë¬´ë¶„ì•¼: {job.get('meta_data', {}).get('job_category', '')}
    í•„ìš” ìŠ¤í‚¬: {required_skills_text}
    ìŠ¤í‚¬ì…‹: {skill_set_text}
    ê²½ë ¥: {job.get('experience', '')}
    """
    metadata = {
        "title": job.get('title', ''),
        "company": job.get('company', ''),
        "url": job.get('url', ''),
        "job_category": job.get('meta_data', {}).get('job_category', ''),
        "experience": job.get('experience', ''),
    }
    documents.append(Document(page_content=content.strip(), metadata=metadata))
print(f"Document ë³€í™˜ ì™„ë£Œ: {len(documents)}ê°œ")

# ì˜ë¯¸ë¡ ì  ê²€ìƒ‰(ì„ë² ë”© ê¸°ë°˜)ìš© ChromaDB ìƒì„± ë° Retriever ì¤€ë¹„
print("ChromaDB ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì¤‘...")
embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
vectorstore = Chroma.from_documents(
    documents=documents,
    embedding=embeddings,
    collection_name="job_postings"
)
chroma_retriever = vectorstore.as_retriever(search_kwargs={"k": 10})
print("ChromaDB ìƒì„± ì™„ë£Œ")

# í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰(BM25) Retriever ì¤€ë¹„
print("BM25 Retriever ìƒì„± ì¤‘...")
bm25_retriever = BM25Retriever.from_documents(documents)
bm25_retriever.k = 10
print("BM25 Retriever ìƒì„± ì™„ë£Œ")

# í•˜ì´ë¸Œë¦¬ë“œ(ì•™ìƒë¸”) Retriever ì •ì˜
class CustomEnsembleRetriever(BaseRetriever):
    """ì—¬ëŸ¬ retrieverë¥¼ ê²°í•©í•˜ì—¬ ê²°ê³¼ë¥¼ ì¢…í•©(ê°€ì¤‘ì¹˜ ë°˜ì˜)"""
    retrievers: List[BaseRetriever]
    weights: List[float]
    def _get_relevant_documents(
        self, query: str, *, run_manager: CallbackManagerForRetrieverRun
    ) -> List[Document]:
        all_results = []
        for retriever, weight in zip(self.retrievers, self.weights):
            results = retriever.invoke(query)
            for doc in results:
                doc.metadata['ensemble_score'] = weight
                all_results.append(doc)
        # ë‚´ìš© ì¼ë¶€(PageContent) ê¸°ì¤€ ì¤‘ë³µ ì œê±° ë° ê°€ì¤‘ì¹˜ í•©ì‚°
        unique_docs = {}
        for doc in all_results:
            doc_id = doc.page_content[:100]
            if doc_id in unique_docs:
                unique_docs[doc_id].metadata['ensemble_score'] += doc.metadata.get('ensemble_score', 0)
            else:
                unique_docs[doc_id] = doc
        sorted_docs = sorted(
            unique_docs.values(), 
            key=lambda x: x.metadata.get('ensemble_score', 0), 
            reverse=True
        )
        return sorted_docs

# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ìƒì„± (ì„ë² ë”©: 60%, BM25: 40%)
ensemble_retriever = CustomEnsembleRetriever(
    retrievers=[chroma_retriever, bm25_retriever],
    weights=[0.6, 0.4]
)
print("Ensemble Retriever ìƒì„± ì™„ë£Œ")

# ì§ë¬´ê¸°ìˆ ì„œ ê°¯ìˆ˜ ë° ìƒ˜í”Œ ì¶œë ¥
print(f"ì§ë¬´ê¸°ìˆ ì„œ ë°ì´í„°: {len(df)}ê°œ")
df.head()

def search_similar_jobs(industry, skill_set, top_k=5):
    """
    ì§ë¬´ê¸°ìˆ ì„œì˜ industryì™€ skill_setì„ ê¸°ë°˜ìœ¼ë¡œ ìœ ì‚¬ ì±„ìš©ê³µê³  ê²€ìƒ‰ (ìµœëŒ€ top_kê°œ ë°˜í™˜)
    """
    skill_set_str = " ".join(skill_set) if isinstance(skill_set, list) else str(skill_set)
    query = f"{industry} {skill_set_str}"
    results = ensemble_retriever.invoke(query)
    return results[:top_k]

# ê²°ê³¼ ì €ì¥ìš© ë³€ìˆ˜
from datetime import datetime
all_results = []

# ì§ë¬´ê¸°ìˆ ì„œ ì „ì²´ì— ëŒ€í•´ ìœ ì‚¬ ì±„ìš©ê³µê³  ê²€ìƒ‰
print("\n" + "="*100)
print("ì „ì²´ ì§ë¬´ê¸°ìˆ ì„œì— ëŒ€í•œ ì±„ìš©ê³µê³  ë§¤ì¹­ ì‹œì‘...")
print("="*100)

for idx, row in df.iterrows():
    industry = row['industry']
    skill_set = row['ê³µí†µ_skill_set']
    job_title = row['ì§ë¬´']
    
    # ê²€ìƒ‰ ì‹¤í–‰
    similar_jobs = search_similar_jobs(industry, skill_set, top_k=5)
    
    # ê²°ê³¼ ì €ì¥
    result_item = {
        'job_title': job_title,
        'industry': industry,
        'skill_set': skill_set[:5] if isinstance(skill_set, list) else str(skill_set)[:100],
        'matched_jobs': []
    }
    
    for i, job in enumerate(similar_jobs, 1):
        result_item['matched_jobs'].append({
            'rank': i,
            'title': job.metadata['title'],
            'company': job.metadata['company'],
            'job_category': job.metadata.get('job_category', 'N/A'),
            'experience': job.metadata.get('experience', 'N/A'),
            'url': job.metadata['url'],
            'score': job.metadata.get('ensemble_score', 0)
        })
    
    all_results.append(result_item)
    
    # ì§„í–‰ìƒí™© ì¶œë ¥
    if (idx + 1) % 10 == 0:
        print(f"ì§„í–‰ ì¤‘... {idx + 1}/{len(df)} ì™„ë£Œ")

print(f"\në§¤ì¹­ ì™„ë£Œ! ì´ {len(all_results)}ê°œ ì§ë¬´ê¸°ìˆ ì„œ ì²˜ë¦¬")

# TXT íŒŒì¼ë¡œ ì €ì¥
def save_results_to_txt(results, filename):
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ TXT íŒŒì¼ë¡œ ì €ì¥"""
    with open(filename, 'w', encoding='utf-8') as f:
        f.write("="*100 + "\n")
        f.write("ì§ë¬´ê¸°ìˆ ì„œ - ì±„ìš©ê³µê³  ë§¤ì¹­ ê²°ê³¼\n")
        f.write(f"ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"ì´ ì§ë¬´ê¸°ìˆ ì„œ ìˆ˜: {len(results)}ê°œ\n")
        f.write(f"ì´ ì±„ìš©ê³µê³  ìˆ˜: {len(job_postings)}ê°œ\n")
        f.write("="*100 + "\n\n")
        
        for idx, result in enumerate(results, 1):
            f.write(f"\n{'='*100}\n")
            f.write(f"[{idx}] ì§ë¬´: {result['job_title']}\n")
            f.write(f"{'='*100}\n")
            f.write(f"Industry: {result['industry']}\n")
            f.write(f"Skill Set (ìƒ˜í”Œ): {result['skill_set']}\n")
            f.write(f"\n{'ì¶”ì²œ ì±„ìš©ê³µê³  Top 5':-^90}\n\n")
            
            for job in result['matched_jobs']:
                f.write(f"{job['rank']}. {job['title']}\n")
                f.write(f"   íšŒì‚¬: {job['company']}\n")
                f.write(f"   ì—…ë¬´ë¶„ì•¼: {job['job_category']}\n")
                f.write(f"   ê²½ë ¥: {job['experience']}\n")
                f.write(f"   ë§¤ì¹­ì ìˆ˜: {job['score']:.2f}\n")
                f.write(f"   URL: {job['url']}\n\n")
    
    print(f"âœ… TXT íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}")

# PDF íŒŒì¼ë¡œ ì €ì¥ (reportlab ì‚¬ìš©)
def save_results_to_pdf(results, filename):
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ PDF íŒŒì¼ë¡œ ì €ì¥ (í•œê¸€ ì§€ì›)"""
    try:
        from reportlab.lib.pagesizes import A4, letter
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.lib.units import inch
        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak
        from reportlab.pdfbase import pdfmetrics
        from reportlab.pdfbase.ttfonts import TTFont
        from reportlab.lib.enums import TA_LEFT, TA_CENTER
        
        # í•œê¸€ í°íŠ¸ ë“±ë¡ ì‹œë„
        try:
            # Windows ê¸°ë³¸ í•œê¸€ í°íŠ¸
            pdfmetrics.registerFont(TTFont('Malgun', 'malgun.ttf'))
            font_name = 'Malgun'
        except:
            try:
                pdfmetrics.registerFont(TTFont('Gulim', 'gulim.ttf'))
                font_name = 'Gulim'
            except:
                print("âš ï¸ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ë¬¸ í°íŠ¸ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                font_name = 'Helvetica'
        
        # PDF ìƒì„±
        doc = SimpleDocTemplate(filename, pagesize=A4)
        story = []
        
        # ìŠ¤íƒ€ì¼ ì •ì˜
        styles = getSampleStyleSheet()
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontName=font_name,
            fontSize=16,
            alignment=TA_CENTER
        )
        heading_style = ParagraphStyle(
            'CustomHeading',
            parent=styles['Heading2'],
            fontName=font_name,
            fontSize=12
        )
        normal_style = ParagraphStyle(
            'CustomNormal',
            parent=styles['Normal'],
            fontName=font_name,
            fontSize=9
        )
        
        # ì œëª©
        story.append(Paragraph("ì§ë¬´ê¸°ìˆ ì„œ - ì±„ìš©ê³µê³  ë§¤ì¹­ ê²°ê³¼", title_style))
        story.append(Spacer(1, 0.2*inch))
        story.append(Paragraph(f"ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", normal_style))
        story.append(Paragraph(f"ì´ ì§ë¬´ê¸°ìˆ ì„œ ìˆ˜: {len(results)}ê°œ | ì´ ì±„ìš©ê³µê³  ìˆ˜: {len(job_postings)}ê°œ", normal_style))
        story.append(Spacer(1, 0.3*inch))
        
        # ê° ê²°ê³¼ ì¶”ê°€
        for idx, result in enumerate(results, 1):
            story.append(Paragraph(f"[{idx}] ì§ë¬´: {result['job_title']}", heading_style))
            story.append(Paragraph(f"Industry: {result['industry']}", normal_style))
            story.append(Paragraph(f"Skill Set: {str(result['skill_set'])[:100]}", normal_style))
            story.append(Spacer(1, 0.1*inch))
            
            story.append(Paragraph("ì¶”ì²œ ì±„ìš©ê³µê³  Top 5", heading_style))
            for job in result['matched_jobs']:
                story.append(Paragraph(
                    f"{job['rank']}. {job['title']} - {job['company']}", 
                    normal_style
                ))
                story.append(Paragraph(
                    f"   ì—…ë¬´ë¶„ì•¼: {job['job_category']} | ê²½ë ¥: {job['experience']} | ì ìˆ˜: {job['score']:.2f}", 
                    normal_style
                ))
                story.append(Paragraph(f"   URL: {job['url']}", normal_style))
                story.append(Spacer(1, 0.05*inch))
            
            story.append(Spacer(1, 0.2*inch))
            
            # 10ê°œë§ˆë‹¤ í˜ì´ì§€ ë‚˜ëˆ„ê¸°
            if idx % 10 == 0:
                story.append(PageBreak())
        
        # PDF ë¹Œë“œ
        doc.build(story)
        print(f"âœ… PDF íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}")
        
    except ImportError:
        print("âš ï¸ reportlab ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        print("   'pip install reportlab' ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
    except Exception as e:
        print(f"âš ï¸ PDF ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

# ê²°ê³¼ íŒŒì¼ ì €ì¥
timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
output_dir = "C:/workspace/Final_project/backend-model/AI_Lab/output"
os.makedirs(output_dir, exist_ok=True)

txt_filename = f"{output_dir}/job_matching_results_{timestamp}.txt"
pdf_filename = f"{output_dir}/job_matching_results_{timestamp}.pdf"

# TXT ì €ì¥
save_results_to_txt(all_results, txt_filename)

# PDF ì €ì¥
save_results_to_pdf(all_results, pdf_filename)

print("\n" + "="*100)
print("ê²°ê³¼ íŒŒì¼ ì €ì¥ ì™„ë£Œ!")
print(f"ğŸ“„ TXT íŒŒì¼: {txt_filename}")
print(f"ğŸ“„ PDF íŒŒì¼: {pdf_filename}")
print("="*100)

# ì²˜ìŒ 3ê°œ ê²°ê³¼ë§Œ ì½˜ì†”ì— ì¶œë ¥
print("\n\n[ê²€ìƒ‰ ê²°ê³¼ ìƒ˜í”Œ - ì²˜ìŒ 3ê°œ]")
for idx, result in enumerate(all_results[:3], 1):
    print(f"\n{'='*100}")
    print(f"[{idx}] ì§ë¬´: {result['job_title']}")
    print(f"Industry: {result['industry']}")
    print(f"{'='*100}")
    for job in result['matched_jobs']:
        print(f"\n{job['rank']}. {job['title']}")
        print(f"   íšŒì‚¬: {job['company']}")
        print(f"   ì—…ë¬´ë¶„ì•¼: {job['job_category']}")
        print(f"   ê²½ë ¥: {job['experience']}")
        print(f"   ë§¤ì¹­ì ìˆ˜: {job['score']:.2f}")
        print(f"   URL: {job['url']}")
