import os
import re
import json
from pathlib import Path
from typing import List, Dict, Any

from dotenv import load_dotenv
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import PydanticOutputParser

# .env ì ìš©
load_dotenv()


class SkillSetOutput(BaseModel):
    """ìŠ¤í‚¬ì…‹ ì¶”ì¶œ ê²°ê³¼ ëª¨ë¸"""
    skill_set: List[str] = Field(description="ì¶”ì¶œëœ ê¸°ìˆ  ìŠ¤íƒ ë¦¬ìŠ¤íŠ¸")


class SkillSetMatcher:
    def __init__(self, job_description_path: str):
        """ì§ë¬´ ê¸°ìˆ ì„œ ë°ì´í„° ë¡œë“œ ë° LLM ì´ˆê¸°í™”"""
        with open(job_description_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        self._extract_skillset_from_data(data)
        self._initialize_llm()

    def _extract_skillset_from_data(self, data: Any):
        if isinstance(data, dict):
            self.common_skill_set = data.get('ê³µí†µ_skill_set', [])
            raw_skill_set = data.get('skill_set', [])
            if not self.common_skill_set and not raw_skill_set:
                raise ValueError("description.jsonì—ì„œ 'ê³µí†µ_skill_set' ë˜ëŠ” 'skill_set' í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            # skill_setì´ ì´ë¯¸ ë°°ì—´ì¸ì§€ ì„¤ëª…ë¬¸ í˜•ì‹ì¸ì§€ í™•ì¸
            self.skill_set = self._process_skill_set(raw_skill_set)
        elif isinstance(data, list):
            self.common_skill_set = []
            all_descriptions = []
            for job_desc in data:
                if isinstance(job_desc, dict):
                    common = job_desc.get('ê³µí†µ_skill_set', [])
                    if isinstance(common, list):
                        self.common_skill_set.extend(common)
                    skill = job_desc.get('skill_set', '')
                    if skill:
                        all_descriptions.append(skill)
            self.common_skill_set = list(set(self.common_skill_set))
            self.skill_set = self._process_skill_set(all_descriptions)
        else:
            raise ValueError(
                f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„° í˜•ì‹ì…ë‹ˆë‹¤. dict ë˜ëŠ” listì—¬ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬ íƒ€ì…: {type(data).__name__}"
            )
        self.all_skills = sorted(list(set(self.common_skill_set + self.skill_set)))

    def _process_skill_set(self, skill_set: Any) -> List[str]:
        """skill_setì„ ì²˜ë¦¬í•˜ì—¬ ìŠ¤í‚¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        
        Args:
            skill_set: ë°°ì—´ í˜•ì‹([str, ...]) ë˜ëŠ” ì„¤ëª…ë¬¸ í˜•ì‹(str ë˜ëŠ” List[str])
        
        Returns:
            ì¶”ì¶œëœ ìŠ¤í‚¬ ë¦¬ìŠ¤íŠ¸
        """
        if not skill_set:
            return []
        
        # ì´ë¯¸ ë°°ì—´ í˜•ì‹ì¸ ê²½ìš° (ê° ìš”ì†Œê°€ ì´ë¯¸ ê°œë³„ ìŠ¤í‚¬ ì´ë¦„)
        if isinstance(skill_set, list):
            # ëª¨ë“  ìš”ì†Œê°€ ë¬¸ìì—´ì´ê³  ê´„í˜¸ê°€ ì—†ëŠ” ê²½ìš° -> ì´ë¯¸ ê°œë³„ ìŠ¤í‚¬ ë°°ì—´
            if all(isinstance(item, str) and '(' not in item for item in skill_set):
                return [skill.strip() for skill in skill_set if skill.strip()]
            # ì„¤ëª…ë¬¸ í˜•ì‹ì¸ ê²½ìš° -> íŒŒì‹± í•„ìš”
            else:
                return self._parse_skill_descriptions(skill_set)
        
        # ë¬¸ìì—´ í˜•ì‹ì¸ ê²½ìš° -> íŒŒì‹± í•„ìš”
        elif isinstance(skill_set, str):
            return self._parse_skill_descriptions([skill_set])
        
        return []

    def _parse_skill_descriptions(self, descriptions: List[str]) -> List[str]:
        """ê¸´ ì„¤ëª…ë¬¸ì—ì„œ ê°œë³„ ìŠ¤í‚¬ ì´ë¦„ ì¶”ì¶œ (ì˜ˆ: "ì›¹í”„ë ˆì„ì›Œí¬(Spring, Django, Flask)")"""
        skills = []
        for desc in descriptions:
            if not desc or not isinstance(desc, str):
                continue
            # ê´„í˜¸ê°€ ìˆëŠ” ì„¤ëª…ë¬¸ í˜•ì‹ì—ì„œ ì¶”ì¶œ
            matches = re.findall(r'\(([^)]+)\)', desc)
            if matches:
                for match in matches:
                    for item in re.split(r'[,/]', match):
                        item = item.strip()
                        if len(item) > 1 and not item.replace(' ', '').replace('-', '').replace('.', '').isalpha():
                            skills.append(item)
                        elif any(c.isalnum() for c in item) and len(item) > 1:
                            skills.append(item)
            # ê´„í˜¸ê°€ ì—†ëŠ” ê²½ìš° ë¬¸ìì—´ ìì²´ë¥¼ ìŠ¤í‚¬ë¡œ ê°„ì£¼ (ì´ë¯¸ ê°œë³„ ìŠ¤í‚¬ ì´ë¦„ì¸ ê²½ìš°)
            else:
                desc = desc.strip()
                if desc and len(desc) > 1:
                    skills.append(desc)
        return list(set(skills))

    def _initialize_llm(self):
        """LLM ë° í”„ë¡¬í”„íŠ¸ ì´ˆê¸°í™”"""
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            raise ValueError(
                "OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n.env íŒŒì¼ ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ì— í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
            )

        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0, api_key=api_key)
        self.parser = PydanticOutputParser(pydantic_object=SkillSetOutput)
        self.prompt = PromptTemplate(
            template=(
                "ë‹¹ì‹ ì˜ ì—­í• : ì±„ìš©ê³µê³ (description) í…ìŠ¤íŠ¸ì—ì„œ ê¸°ìˆ  ìŠ¤íƒì„ ì¶”ì¶œí•˜ëŠ” ì—”ì§„.\n"
                "common_skill_set ê³¼ skill_set ë‚´ì—ì„œë§Œ ì„ íƒí•˜ë©°, ê·¸ ì™¸ ìƒˆë¡œìš´ ìŠ¤í‚¬ì€ ìƒì„±í•˜ì§€ ì•ŠëŠ”ë‹¤.\n\n"
                "ê·œì¹™:\n"
                "1) common_skill_set âˆª skill_set ì•ˆì— ìˆëŠ” ê¸°ìˆ ë§Œ ì¶”ì¶œí•œë‹¤.\n"
                "2) ìŠ¤í‚¬ëª…ì´ descriptionì— ë“±ì¥í•˜ë©´ ìœ ì‚¬/ë™ì˜/ì² ì ë³€í˜•/ëŒ€ì†Œë¬¸ì ì°¨ì´ë¥¼ í—ˆìš©í•˜ë˜, "
                "ê²°ê³¼ëŠ” canonical ëª…ì¹­ìœ¼ë¡œ ì¶œë ¥í•œë‹¤.\n"
                "   ì˜ˆ: Node, NodeJS â†’ Node.js / ReactJS â†’ React / PyTorch â†’ PyTorch\n"
                "3) ì†Œí”„íŠ¸ ìŠ¤í‚¬, ì„±í–¥, ì—…ë¬´ ë°©ì‹, ë„ë©”ì¸ í‚¤ì›Œë“œëŠ” ì œì™¸í•œë‹¤.\n"
                "   ì˜ˆ: ì†Œí†µëŠ¥ë ¥, ë¬¸ì œ í•´ê²°, í•€í…Œí¬, ì• ìì¼ ë“± ì œì™¸.\n"
                '4) "ìš°ëŒ€", "ì„ í˜¸", "ê²½í—˜ ìˆìœ¼ë©´ ê°€ì‚°ì "ë“±ì˜ ë¬¸ë§¥ì—ì„œë„ ê¸°ìˆ ëª…ë§Œ ë“±ì¥í•˜ë©´ í¬í•¨í•œë‹¤.\n'
                "5) ìµœì¢… ì¶œë ¥ì€ ì¤‘ë³µ ì œê±°, ì•ŒíŒŒë²³ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬.\n\n"
                "ì‚¬ìš© ê°€ëŠ¥í•œ ìŠ¤í‚¬ ëª©ë¡:\n"
                "{all_skills}\n\n"
                "ì±„ìš©ê³µê³  ë‚´ìš©:\n"
                "{description}\n\n"
                "{format_instructions}\n\n"
                "ì¶œë ¥ ì˜ˆì‹œ:\n"
                "{{\"skill_set\": [\"AWS\", \"Docker\", \"Java\", \"Kubernetes\", \"Python\", \"Spring Boot\"]}}"
            ),
            input_variables=["all_skills", "description"],
            partial_variables={"format_instructions": self.parser.get_format_instructions()}
        )

    def match_job_to_skillset(self, job: Dict[str, Any]) -> Dict[str, Any]:
        """ë‹¨ì¼ jobì— ëŒ€í•´ LLMì„ í™œìš©í•˜ì—¬ skill_set ì¶”ì¶œ"""
        description = job.get('description', '')
        title = job.get('title', '')
        full_text = f"ì œëª©: {title}\n\n{description}"
        if len(full_text.strip()) < 50:
            print(f"  âš ï¸  í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ì•„ ìŠ¤í‚µ: {title}")
            return {'matched': False, 'match_score': 0, 'skill_set': []}
        try:
            chain = self.prompt | self.llm | self.parser
            result = chain.invoke({
                "all_skills": ", ".join(self.all_skills),
                "description": full_text[:4000],
            })
            extracted_skills = sorted(result.skill_set)
            if extracted_skills:
                return {'matched': True, 'match_score': len(extracted_skills), 'skill_set': extracted_skills}
            return {'matched': False, 'match_score': 0, 'skill_set': []}
        except Exception as e:
            print(f"  âŒ LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return {'matched': False, 'match_score': 0, 'skill_set': [], 'error': str(e)}

    def process_jobs_file(self, input_path: str, output_path: str):
        """jobs íŒŒì¼ ì²˜ë¦¬ ë° skill_set ì •ë³´ ì¶”ê°€"""
        print(f"\n{'='*60}\nğŸ“ ì²˜ë¦¬ ì¤‘: {input_path}\n{'='*60}")
        with open(input_path, 'r', encoding='utf-8') as f:
            jobs = json.load(f)
        matched_count, unmatched_count, total_skills = 0, 0, 0

        for idx, job in enumerate(jobs, 1):
            print(f"\n[{idx}/{len(jobs)}] {job.get('title', 'Unknown')}")
            skill_info = self.match_job_to_skillset(job)
            if skill_info['matched']:
                matched_count += 1
                skill_count = len(skill_info['skill_set'])
                total_skills += skill_count
                skills_preview = ', '.join(skill_info['skill_set'][:5])
                print(f"  âœ… {skill_count}ê°œ ìŠ¤í‚¬ ì¶”ì¶œ: {skills_preview}{'...' if skill_count > 5 else ''}")
            else:
                unmatched_count += 1
                print("  âš ï¸  ìŠ¤í‚¬ ì¶”ì¶œ ì‹¤íŒ¨")
            job['skill_set_info'] = skill_info

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(jobs, f, ensure_ascii=False, indent=2)

        print(
            f"\n{'='*60}\nğŸ“Š ì²˜ë¦¬ ì™„ë£Œ ìš”ì•½\n{'='*60}\n"
            f"  - ì´ ì±„ìš©ê³µê³ : {len(jobs)}ê°œ\n"
            f"  - ë§¤ì¹­ ì„±ê³µ: {matched_count}ê°œ ({matched_count/len(jobs)*100:.1f}%)\n"
            f"  - ë§¤ì¹­ ì‹¤íŒ¨: {unmatched_count}ê°œ ({unmatched_count/len(jobs)*100:.1f}%)"
        )
        if matched_count > 0:
            print(f"  - í‰ê·  ì¶”ì¶œ ìŠ¤í‚¬ ìˆ˜: {total_skills/matched_count:.1f}ê°œ")
        print(f"  - ì €ì¥ ìœ„ì¹˜: {output_path}\n{'='*60}\n")
        return matched_count, unmatched_count


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    description_path = Path(__file__).parent / 'description.json'
    data_dir = Path(r"C:\workspace\Final_project\backend-model\data")

    print("\n" + "=" * 60)
    print("ğŸš€ LLM ê¸°ë°˜ Skill Set ì¶”ì¶œ ì‹œì‘")
    print("=" * 60)
    print(f"ğŸ“‹ ìŠ¤í‚¬ ëª©ë¡ íŒŒì¼: {description_path}")
    print(f"ğŸ“‚ ë°ì´í„° ë””ë ‰í† ë¦¬: {data_dir}")

    if not description_path.exists():
        print(f"\nâŒ ì˜¤ë¥˜: description.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n   ì°¾ëŠ” ê²½ë¡œ: {description_path}\n   íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    if not data_dir.exists():
        print(f"\nâŒ ì˜¤ë¥˜: ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n   ì°¾ëŠ” ê²½ë¡œ: {data_dir}\n   ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    try:
        matcher = SkillSetMatcher(str(description_path))
        print(f"âœ… ì´ {len(matcher.all_skills)}ê°œì˜ ìŠ¤í‚¬ ë¡œë“œ ì™„ë£Œ\n   - ê³µí†µ ìŠ¤í‚¬: {len(matcher.common_skill_set)}ê°œ\n   - ì§ë¬´ë³„ ìŠ¤í‚¬: {len(matcher.skill_set)}ê°œ")
    except ValueError as e:
        print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        if "OPENAI_API_KEY" in str(e):
            print("\nğŸ’¡ í•´ê²° ë°©ë²•:\n   .env íŒŒì¼ì— ë‹¤ìŒê³¼ ê°™ì´ ì¶”ê°€í•˜ì„¸ìš”: OPENAI_API_KEY=your-api-key\n   ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ì„¸ìš” (Windows: set, Linux/Mac: export)")
        return
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return

    jobs_files = list(data_dir.glob('*_jobs.json'))
    if not jobs_files:
        print(f"\nâš ï¸  {data_dir}ì—ì„œ *_jobs.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ“ ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜: {len(jobs_files)}")
    total_matched, total_unmatched = 0, 0
    for jobs_file in jobs_files:
        try:
            matched, unmatched = matcher.process_jobs_file(str(jobs_file), str(jobs_file))
            total_matched += matched
            total_unmatched += unmatched
        except Exception as e:
            print(f"\nâŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {jobs_file}\n   ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}")
            continue

    print("\n" + "=" * 60)
    print("ğŸ‰ ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ")
    print("=" * 60)
    print(f"  - ì „ì²´ ë§¤ì¹­ ì„±ê³µ: {total_matched}ê°œ")
    print(f"  - ì „ì²´ ë§¤ì¹­ ì‹¤íŒ¨: {total_unmatched}ê°œ")
    total = total_matched + total_unmatched
    if total > 0:
        print(f"  - ë§¤ì¹­ ì„±ê³µë¥ : {total_matched / total * 100:.2f}%")
    print(f"  - ê²°ê³¼ íŒŒì¼ ìœ„ì¹˜: {data_dir}")
    print("=" * 60 + "\n")


if __name__ == "__main__":
    main()