import json
from pathlib import Path
from typing import List, Dict, Any
import os
import re
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field

# .env ì§€ì›ì„ ìœ„í•´ dotenv import ë° ì ìš©
from dotenv import load_dotenv
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
class SkillSetOutput(BaseModel):
    
    """ìŠ¤í‚¬ì…‹ ì¶”ì¶œ ê²°ê³¼ ëª¨ë¸"""
    skill_set: List[str] = Field(description="ì¶”ì¶œëœ ê¸°ìˆ  ìŠ¤íƒ ë¦¬ìŠ¤íŠ¸")

class SkillSetMatcher:
    def __init__(self, job_description_path: str):
        """ì§ë¬´ ê¸°ìˆ ì„œ ë°ì´í„° ë¡œë“œ ë° LLM ì´ˆê¸°í™”"""
        with open(job_description_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # ë°ì´í„° í˜•ì‹ì— ë”°ë¼ ì²˜ë¦¬
        if isinstance(data, dict):
            self.common_skill_set = data.get('ê³µí†µ_skill_set', [])
            raw_skill_set = data.get('skill_set', [])
            if not self.common_skill_set and not raw_skill_set:
                raise ValueError("description.jsonì—ì„œ 'ê³µí†µ_skill_set' ë˜ëŠ” 'skill_set' í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            self.skill_set = self._parse_skill_descriptions(raw_skill_set)
            
        elif isinstance(data, list):
            self.common_skill_set = []
            all_descriptions = []
            for job_desc in data:
                if isinstance(job_desc, dict):
                    common = job_desc.get('ê³µí†µ_skill_set', [])
                    if isinstance(common, list):
                        self.common_skill_set.extend(common)
                    skill = job_desc.get('skill_set', '')
                    if skill:
                        all_descriptions.append(skill)
            self.common_skill_set = list(set(self.common_skill_set))
            self.skill_set = self._parse_skill_descriptions(all_descriptions)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„° í˜•ì‹ì…ë‹ˆë‹¤. dict ë˜ëŠ” listì—¬ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬ íƒ€ì…: {type(data).__name__}")
        self.all_skills = list(set(self.common_skill_set + self.skill_set))
        self._initialize_llm()
    
    def _parse_skill_descriptions(self, descriptions: List[str]) -> List[str]:
        """ê¸´ ì„¤ëª…ë¬¸ì—ì„œ ê°œë³„ ìŠ¤í‚¬ ì´ë¦„ ì¶”ì¶œ"""
        skills = []
        for desc in descriptions:
            bracket_matches = re.findall(r'\(([^)]+)\)', desc)
            for match in bracket_matches:
                items = re.split(r'[,/]', match)
                for item in items:
                    item = item.strip()
                    if len(item) > 1 and not item.replace(' ', '').replace('-', '').replace('.', '').isalpha():
                        skills.append(item)
                    elif any(c.isalnum() for c in item) and len(item) > 1:
                        skills.append(item)
        return list(set(skills))
    
    def _initialize_llm(self):
        """LLM ë° í”„ë¡¬í”„íŠ¸ ì´ˆê¸°í™”"""
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n.env íŒŒì¼ ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ì— í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0,
            api_key=api_key
        )
        self.parser = PydanticOutputParser(pydantic_object=SkillSetOutput)
        self.prompt = PromptTemplate(
            template="""ë‹¹ì‹ ì˜ ì—­í• : ì±„ìš©ê³µê³ (description) í…ìŠ¤íŠ¸ì—ì„œ ê¸°ìˆ  ìŠ¤íƒì„ ì¶”ì¶œí•˜ëŠ” ì—”ì§„.
common_skill_set ê³¼ skill_set ë‚´ì—ì„œë§Œ ì„ íƒí•˜ë©°, ê·¸ ì™¸ ìƒˆë¡œìš´ ìŠ¤í‚¬ì€ ìƒì„±í•˜ì§€ ì•ŠëŠ”ë‹¤.

ê·œì¹™:
1) common_skill_set âˆª skill_set ì•ˆì— ìˆëŠ” ê¸°ìˆ ë§Œ ì¶”ì¶œí•œë‹¤.
2) ìŠ¤í‚¬ëª…ì´ descriptionì— ë“±ì¥í•˜ë©´ ìœ ì‚¬/ë™ì˜/ì² ì ë³€í˜•/ëŒ€ì†Œë¬¸ì ì°¨ì´ë¥¼ í—ˆìš©í•˜ë˜, ê²°ê³¼ëŠ” canonical ëª…ì¹­ìœ¼ë¡œ ì¶œë ¥í•œë‹¤.
   ì˜ˆ: Node, NodeJS â†’ Node.js / ReactJS â†’ React / PyTorch â†’ PyTorch
3) ì†Œí”„íŠ¸ ìŠ¤í‚¬, ì„±í–¥, ì—…ë¬´ ë°©ì‹, ë„ë©”ì¸ í‚¤ì›Œë“œëŠ” ì œì™¸í•œë‹¤.
   ì˜ˆ: ì†Œí†µëŠ¥ë ¥, ë¬¸ì œ í•´ê²°, í•€í…Œí¬, ì• ìì¼ ë“± ì œì™¸.
4) "ìš°ëŒ€", "ì„ í˜¸", "ê²½í—˜ ìˆìœ¼ë©´ ê°€ì‚°ì "ë“±ì˜ ë¬¸ë§¥ì—ì„œë„ ê¸°ìˆ ëª…ë§Œ ë“±ì¥í•˜ë©´ í¬í•¨í•œë‹¤.
5) ìµœì¢… ì¶œë ¥ì€ ì¤‘ë³µ ì œê±°, ì•ŒíŒŒë²³ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬.

ì‚¬ìš© ê°€ëŠ¥í•œ ìŠ¤í‚¬ ëª©ë¡:
{all_skills}

ì±„ìš©ê³µê³  ë‚´ìš©:
{description}

{format_instructions}

ì¶œë ¥ ì˜ˆì‹œ:
{{"skill_set": ["AWS", "Docker", "Java", "Kubernetes", "Python", "Spring Boot"]}}
""",
            input_variables=["all_skills", "description"],
            partial_variables={"format_instructions": self.parser.get_format_instructions()}
        )
    
    def match_job_to_skillset(self, job: Dict[str, Any]) -> Dict[str, Any]:
        """ë‹¨ì¼ jobì— ëŒ€í•´ LLMì„ í™œìš©í•˜ì—¬ skill_set ì¶”ì¶œ"""
        description = job.get('description', '')
        title = job.get('title', '')
        full_text = f"ì œëª©: {title}\n\n{description}"
        if len(full_text.strip()) < 50:
            print(f"  âš ï¸  í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ì•„ ìŠ¤í‚µ: {title}")
            return {
                'matched': False,
                'match_score': 0,
                'skill_set': []
            }
        try:
            chain = self.prompt | self.llm | self.parser
            result = chain.invoke({
                "all_skills": ", ".join(self.all_skills),
                "description": full_text[:4000]
            })
            extracted_skills = result.skill_set
            extracted_skills.sort()
            if extracted_skills:
                return {
                    'matched': True,
                    'match_score': len(extracted_skills),
                    'skill_set': extracted_skills
                }
            else:
                return {
                    'matched': False,
                    'match_score': 0,
                    'skill_set': []
                }
        except Exception as e:
            print(f"  âŒ LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return {
                'matched': False,
                'match_score': 0,
                'skill_set': [],
                'error': str(e)
            }
    
    def process_jobs_file(self, input_path: str, output_path: str):
        """jobs íŒŒì¼ ì²˜ë¦¬ ë° skill_set ì •ë³´ ì¶”ê°€"""
        print(f"\n{'='*60}")
        print(f"ğŸ“ ì²˜ë¦¬ ì¤‘: {input_path}")
        print(f"{'='*60}")
        with open(input_path, 'r', encoding='utf-8') as f:
            jobs = json.load(f)
        matched_count = 0
        unmatched_count = 0
        total_skills_extracted = 0
        for idx, job in enumerate(jobs, 1):
            print(f"\n[{idx}/{len(jobs)}] {job.get('title', 'Unknown')}")
            skill_info = self.match_job_to_skillset(job)
            if skill_info['matched']:
                matched_count += 1
                skill_count = len(skill_info['skill_set'])
                total_skills_extracted += skill_count
                print(f"  âœ… {skill_count}ê°œ ìŠ¤í‚¬ ì¶”ì¶œ: {', '.join(skill_info['skill_set'][:5])}{'...' if skill_count > 5 else ''}")
            else:
                unmatched_count += 1
                print(f"  âš ï¸  ìŠ¤í‚¬ ì¶”ì¶œ ì‹¤íŒ¨")
            job['skill_set_info'] = skill_info
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(jobs, f, ensure_ascii=False, indent=2)
        print(f"\n{'='*60}")
        print(f"ğŸ“Š ì²˜ë¦¬ ì™„ë£Œ ìš”ì•½")
        print(f"{'='*60}")
        print(f"  - ì´ ì±„ìš©ê³µê³ : {len(jobs)}ê°œ")
        print(f"  - ë§¤ì¹­ ì„±ê³µ: {matched_count}ê°œ ({matched_count/len(jobs)*100:.1f}%)")
        print(f"  - ë§¤ì¹­ ì‹¤íŒ¨: {unmatched_count}ê°œ ({unmatched_count/len(jobs)*100:.1f}%)")
        if matched_count > 0:
            print(f"  - í‰ê·  ì¶”ì¶œ ìŠ¤í‚¬ ìˆ˜: {total_skills_extracted/matched_count:.1f}ê°œ")
        print(f"  - ì €ì¥ ìœ„ì¹˜: {output_path}")
        print(f"{'='*60}\n")
        return matched_count, unmatched_count

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    description_path = Path(__file__).parent / 'description.json'
    data_dir = Path(r"C:\workspace\Final_project\backend-model\data")
    
    print("\n" + "="*60)
    print("ğŸš€ LLM ê¸°ë°˜ Skill Set ì¶”ì¶œ ì‹œì‘")
    print("="*60)
    print(f"ğŸ“‹ ìŠ¤í‚¬ ëª©ë¡ íŒŒì¼: {description_path}")
    print(f"ğŸ“‚ ë°ì´í„° ë””ë ‰í† ë¦¬: {data_dir}")
    if not description_path.exists():
        print(f"\nâŒ ì˜¤ë¥˜: description.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   ì°¾ëŠ” ê²½ë¡œ: {description_path}")
        print(f"   íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    if not data_dir.exists():
        print(f"\nâŒ ì˜¤ë¥˜: ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   ì°¾ëŠ” ê²½ë¡œ: {data_dir}")
        print(f"   ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    try:
        matcher = SkillSetMatcher(str(description_path))
        print(f"âœ… ì´ {len(matcher.all_skills)}ê°œì˜ ìŠ¤í‚¬ ë¡œë“œ ì™„ë£Œ")
        print(f"   - ê³µí†µ ìŠ¤í‚¬: {len(matcher.common_skill_set)}ê°œ")
        print(f"   - ì§ë¬´ë³„ ìŠ¤í‚¬: {len(matcher.skill_set)}ê°œ")
    except ValueError as e:
        print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        # .envë„ ì§€ì›í•˜ê³  ìˆìœ¼ë¯€ë¡œ ì•ˆë‚´ ë©˜íŠ¸ë„ ë³´ê°•
        if "OPENAI_API_KEY" in str(e):
            print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
            print("   .env íŒŒì¼ì— ë‹¤ìŒê³¼ ê°™ì´ ì¶”ê°€í•˜ì„¸ìš”: OPENAI_API_KEY=your-api-key")
            print("   ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ì„¸ìš” (Windows: set, Linux/Mac: export)")
        return
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return
    jobs_files = list(data_dir.glob('*_jobs.json'))
    if not jobs_files:
        print(f"\nâš ï¸  {data_dir}ì—ì„œ *_jobs.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    print(f"ğŸ“ ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜: {len(jobs_files)}")
    total_matched = 0
    total_unmatched = 0
    for jobs_file in jobs_files:
        try:
            matched, unmatched = matcher.process_jobs_file(str(jobs_file), str(jobs_file))
            total_matched += matched
            total_unmatched += unmatched
        except Exception as e:
            print(f"\nâŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {jobs_file}")
            print(f"   ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}")
            continue
    print("\n" + "="*60)
    print("ğŸ‰ ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ")
    print("="*60)
    print(f"  - ì „ì²´ ë§¤ì¹­ ì„±ê³µ: {total_matched}ê°œ")
    print(f"  - ì „ì²´ ë§¤ì¹­ ì‹¤íŒ¨: {total_unmatched}ê°œ")
    total = total_matched + total_unmatched
    if total > 0:
        print(f"  - ë§¤ì¹­ ì„±ê³µë¥ : {total_matched / total * 100:.2f}%")
    print(f"  - ê²°ê³¼ íŒŒì¼ ìœ„ì¹˜: {data_dir}")
    print("="*60 + "\n")

if __name__ == "__main__":
    main()